{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "- **Airflow** is an open-source platform for developing, scheduling, and monitoring batch-oriented workflows.\n",
    "- **Airflow** is a platform that lets you build and run workflows. A workflow is represented as a **DAG (a Directed Acyclic Graph)**, and contains individual pieces of work called Tasks, arranged with dependencies and data flows taken into account.\n",
    "    \n",
    "    ```py\n",
    "    # Example of DAG\n",
    "    from datetime import datetime\n",
    "    from airflow import DAG\n",
    "    from airflow.decorators import task\n",
    "    from airflow.operators.bash import BashOperator\n",
    "\n",
    "    # A DAG represents a workflow, a collection of tasks\n",
    "    with DAG(dag_id=\"demo\", start_date=datetime(2022, 1, 1), schedule=\"0 0 * * *\") as dag:\n",
    "        # Tasks are represented as operators\n",
    "    hello = BashOperator(task_id=\"hello\", bash_command=\"echo hello\")\n",
    "\n",
    "    @task()\n",
    "    def airflow():\n",
    "        print(\"airflow\")\n",
    "\n",
    "    # Set dependencies between tasks\n",
    "    hello >> airflow()\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAG\n",
    "- **DAG (Directed Acyclic Graph)** is the core concept of Airflow, collecting Tasks together, organized with dependencies and relationships to say how they should run. The **DAG** itself doesn’t care about what is happening inside the tasks; it is merely concerned with how to execute them - the order to run them in, how many times to retry them, if they have timeouts, and so on.\n",
    "    \n",
    "    ![image.png](https://airflow.apache.org/docs/apache-airflow/stable/_images/basic-dag.png)\n",
    "    > Based on the example above. This DAG defines four Tasks - A, B, C, and D - and dictates the order in which they have to run, and which tasks depend on what others. It will also say how often to run the DAG - maybe “every 5 minutes starting tomorrow”, or “every day since January 1st, 2020”.\n",
    "\n",
    "- Three ways to declare a DAG:\n",
    "    - using Context Manager (`with` statement):\n",
    "        ```py\n",
    "        # Example\n",
    "        import datetime\n",
    "\n",
    "        from airflow import DAG\n",
    "        from airflow.operators.empty import EmptyOperator\n",
    "\n",
    "        with DAG(\n",
    "            dag_id=\"my_dag_name\",\n",
    "            start_date=datetime.datetime(2021, 1, 1),\n",
    "            schedule=\"@daily\",\n",
    "        ):\n",
    "            EmptyOperator(task_id=\"task\")\n",
    "        ```\n",
    "    - using standard constructor:\n",
    "        ```py\n",
    "        # Example\n",
    "        import datetime\n",
    "\n",
    "        from airflow import DAG\n",
    "        from airflow.operators.empty import EmptyOperator\n",
    "\n",
    "        my_dag = DAG(\n",
    "            dag_id=\"my_dag_name\",\n",
    "            start_date=datetime.datetime(2021, 1, 1),\n",
    "            schedule=\"@daily\",\n",
    "        )\n",
    "        EmptyOperator(task_id=\"task\", dag=my_dag)\n",
    "        ```\n",
    "    - using `@dag` decorator:\n",
    "        ```py\n",
    "        # Example\n",
    "        import datetime\n",
    "\n",
    "        from airflow.decorators import dag\n",
    "        from airflow.operators.empty import EmptyOperator\n",
    "\n",
    "\n",
    "        @dag(start_date=datetime.datetime(2021, 1, 1), schedule=\"@daily\")\n",
    "        def generate_dag():\n",
    "            EmptyOperator(task_id=\"task\")\n",
    "\n",
    "\n",
    "        generate_dag()\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task/Operators\n",
    "- A **Task** is the basic unit of execution in Airflow. Tasks are arranged into DAGs, and then have upstream and downstream dependencies set between them into order to express the order they should run in.\n",
    "    ```py\n",
    "    # Set dependencies between tasks using bitshift (>>) operators\n",
    "    first_task >> second_task\n",
    "\n",
    "    # or using set_downstream()\n",
    "    first_task.set_downstream(second_task)\n",
    "\n",
    "    # or using set_upstream()\n",
    "    second_task.set_upstream(first_task)\n",
    "    ```\n",
    "- An **Operator** is conceptually a template for a predefined Task, that you can just define declaratively inside your DAG\n",
    "- Airflow has a very extensive set of operators available, with some built-in to the core or pre-installed providers. Some popular operators include:\n",
    "    - BashOperator - executes a bash command\n",
    "    - PythonOperator - calls an arbitrary Python function\n",
    "    - EmailOperator - sends an email\n",
    "    - For a list of all core operators, see: [Core Operators and Hooks Reference.](https://airflow.apache.org/docs/apache-airflow/stable/operators-and-hooks-ref.html)\n",
    "    ```py\n",
    "    # Example\n",
    "    with DAG(\"my-dag\") as dag:\n",
    "        # create task using HttpOperator\n",
    "        ping = HttpOperator(endpoint=\"http://example.com/update/\")\n",
    "\n",
    "        # create task using EmailOperator\n",
    "        email = EmailOperator(to=\"admin@example.com\", subject=\"Update complete\")\n",
    "\n",
    "        # set dependencies between tasks\n",
    "        ping >> email\n",
    "    ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling\n",
    "\n",
    "- You may set your DAG to run on a simple **schedule** by setting its `schedule` argument to either:\n",
    "    - a cron expression\n",
    "        - **Cron** is a job scheduler on Unix-like operating systems.\n",
    "        - The actions of cron are driven by a **crontab** (cron table)\n",
    "            ```\n",
    "            # ┌───────────── minute (0–59)\n",
    "            # │ ┌───────────── hour (0–23)\n",
    "            # │ │ ┌───────────── day of the month (1–31)\n",
    "            # │ │ │ ┌───────────── month (1–12)\n",
    "            # │ │ │ │ ┌───────────── day of the week (0–6) (Sunday to Saturday;\n",
    "            # │ │ │ │ │                                   7 is also Sunday on some systems)\n",
    "            # │ │ │ │ │\n",
    "            # │ │ │ │ │\n",
    "            # * * * * * <command to execute>\n",
    "        - To learn more about Cron, you can check https://crontab.guru/ for more.\n",
    "    - a `datetime.timedelta` object, \n",
    "    - or one of the Cron Presets.\n",
    "        - Cron Presets is a predefined cron expression that included in Airflow.\n",
    "        - List of presets https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/cron.html#cron-presets\n",
    "- Example DAG that implements scheduling:\n",
    "    ```py\n",
    "    # using cron expression\n",
    "    with DAG(\"cron_expression_dag\", schedule=\"0 0 * * *\"): # will run the DAG every 00:00\n",
    "    ...\n",
    "\n",
    "    # using cron preset\n",
    "    with DAG(\"cron_preset_dag\", schedule=\"@once\"): # will run the DAG once\n",
    "        ...\n",
    "\n",
    "    # using datetime.timedelta object\n",
    "    with DAG(\"timedelta_dag\", schedule=datetime.timedelta(days=1)): # will run the DAG every hour\n",
    "        ...\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- Airflow Core Concepts https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/index.html\n",
    "- Scheduling https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/cron.html\n",
    "- Cron https://en.wikipedia.org/wiki/Cron#CRON_expression\n",
    "- Schedule DAGs in Airflow https://www.astronomer.io/docs/learn/scheduling-in-airflow"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
